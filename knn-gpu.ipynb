{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport time\nfrom sklearn.datasets import load_digits\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import pairwise_distances, accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom multiprocessing import Pool, cpu_count\nimport pandas as pd","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- Global variables for worker processes ---\n_global_data = None\n_global_y = None","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def init_worker(data, y):\n    \"\"\"Initialize each worker with the dataset once.\"\"\"\n    global _global_data, _global_y\n    _global_data = data\n    _global_y = y\n\ndef knn_batch(args):\n    \"\"\"Worker function (now returns a 2D array of labels).\"\"\"\n    query_batch, k = args\n    dists = pairwise_distances(query_batch, _global_data)\n    indices = np.argsort(dists, axis=1)[:, :k]\n    return _global_y[indices]  # Directly return 2D array (shape: [batch_size, k])\n\ndef parallel_knn(queries, k, n_jobs=4):\n    \"\"\"Parallel KNN with shared data.\"\"\"\n    query_batches = np.array_split(queries, n_jobs)\n    args = [(q, k) for q in query_batches]\n    with Pool(processes=n_jobs, initializer=init_worker, initargs=(_global_data, _global_y)) as pool:\n        results = pool.map(knn_batch, args)\n    return np.vstack(results)  # Now works with 2D arrays\n\ndef load_cifar_csv(csv_path='C:/Users/Admin/Desktop/pdcproj/cifar10_spark/cifar10.csv'):\n    df = pd.read_csv(csv_path)\n    X = df.drop('label', axis=1).values\n    y = df['label'].values\n    X = X.astype('float32') / 255.0\n    return X, y","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- Main script ---\ndef benchmark_knn(X, y):\n    test_fraction_results = []\n    dataset_size_results = []\n\n    test_sizes = np.linspace(0.05, 0.5, 10)\n    train_fracs = np.linspace(0.1, 1.0, 10)\n\n    # Fixed k for this benchmark\n    k = 5\n\n    # --- Test fraction benchmark ---\n    for test_frac in test_sizes:\n        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_frac, stratify=y, shuffle=True, random_state=42)\n        _global_data = X_train\n        _global_y = y_train\n\n        # Parallel KNN\n        start = time.time()\n        knn_indices_parallel = parallel_knn(X_test, k, n_jobs=4)\n        parallel_time = time.time() - start\n\n        # Sklearn KNN\n        knn = KNeighborsClassifier(n_neighbors=k)\n        knn.fit(X_train, y_train)\n        start = time.time()\n        _ = knn.predict(X_test)\n        sklearn_time = time.time() - start\n\n        test_fraction_results.append((test_frac, parallel_time, sklearn_time))\n\n    # --- Dataset size benchmark ---\n    X_full_train, X_test, y_full_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, shuffle=True, random_state=42)\n\n    for frac in train_fracs:\n        n_samples = int(len(X_full_train) * frac)\n        X_train = X_full_train[:n_samples]\n        y_train = y_full_train[:n_samples]\n        _global_data = X_train\n        _global_y = y_train\n\n        # Parallel KNN\n        start = time.time()\n        knn_indices_parallel = parallel_knn(X_test, k, n_jobs=4)\n        parallel_time = time.time() - start\n\n        # Sklearn KNN\n        knn = KNeighborsClassifier(n_neighbors=k)\n        knn.fit(X_train, y_train)\n        start = time.time()\n        _ = knn.predict(X_test)\n        sklearn_time = time.time() - start\n\n        dataset_size_results.append((len(X_train), parallel_time, sklearn_time))\n\n    # --- Plotting ---\n    test_frac_arr = np.array(test_fraction_results)\n    data_size_arr = np.array(dataset_size_results)\n\n    plt.figure(figsize=(14, 6))\n\n    plt.subplot(1, 2, 1)\n    plt.plot(test_frac_arr[:, 0], test_frac_arr[:, 1], 'o-', label='Parallel')\n    plt.plot(test_frac_arr[:, 0], test_frac_arr[:, 2], 's-', label='Sklearn')\n    plt.xlabel('Test Set Fraction')\n    plt.ylabel('Prediction Time (s)')\n    plt.title('Effect of Test Set Size on Prediction Time')\n    plt.legend()\n\n    plt.subplot(1, 2, 2)\n    plt.plot(data_size_arr[:, 0], data_size_arr[:, 1], 'o-', label='Parallel')\n    plt.plot(data_size_arr[:, 0], data_size_arr[:, 2], 's-', label='Sklearn')\n    plt.xlabel('Training Set Size')\n    plt.ylabel('Prediction Time (s)')\n    plt.title('Effect of Training Set Size on Prediction Time')\n    plt.legend()\n\n    plt.tight_layout()\n    plt.show()\n\n    return test_fraction_results, dataset_size_results\n\n# Load data and run benchmark\nX, y = load_cifar_csv()\ntest_fraction_results, dataset_size_results = benchmark_knn(X, y)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}